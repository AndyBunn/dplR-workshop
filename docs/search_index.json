[["index.html", "Using R for Tree-Ring Analysis Chapter 1 Preamble", " Using R for Tree-Ring Analysis Andy Bunn, Mikko Korpela 04-June-2021 Chapter 1 Preamble R is both a programing language and a software environment for statistical computing. It is free and open-source, licensed under the GNU General Public License. The Dendrochronology Program Library in R (dplR) is a free powerful add-on package for R that performs many of the standard tasks in tree-ring analysis including cross-dating, detrending, chronology building, spectral and wavelet analyses, and so on. In this workshop, we will use example ring-width files from the ITRDB to demonstrate the functionality of dplR. The R environment is powerful and flexible and its use allows great transparency in presenting data results. An advantage of dplR’s open-source licensing is that one has the option to modify or add to the library’s functionality for performing specific experiments or producing custom figures. In the following pages we will cover the basics of dplR, crossdating, and some limited time-series analysis. Users should be familiar with the basics of dendrochronology and concepts like detrending, autocorrelation, spectral analysis and so on. If this is all new to you – you should proceed immediately to a good primer on dendrochronology like Fritts (2001) or the Cook Book (1990). These pages are not intended to teach you about how to do tree-ring analysis. They are intended to teach you how to use R for dendro. Please note! This is a very drafty document and there are typos and all kinds of silliness in it. "],["introduction.html", "Chapter 2 Introduction 2.1 Before Starting 2.2 Getting Help with R 2.3 Citing R, dplR, and other packages", " Chapter 2 Introduction The R language and programming environment is now commonly used in dendrochronology. R is the world’s preeminent open-source statistical computing software and its power can be harnessed for tree-ring science through the contribution of add-on packages which are freely available on the internet. There are now many R packages for working with dendro data from measuring (measuRing) to standardization and chronology building (dplR, detrendeR), to fire history (burnr) to disturbance (TRADER) to climate-growth analysis (treeclim, pointRes, dendroTools, BIOdry) to working with data from dendrometers (dendrometeR) and cell anatomy (tracheideR, RAPTOR). Although extremely powerful, R has a steep learning curve that has lead some to postpone using it in their own work. In these pages we will demonstrate the ways in which analysts can work with tree-ring data in R over the entire life cycle of a project in a transparent and reproducible way – from initial measuring of the wood to statistical tests to producing publication-quality graphics. These pages are written as a demonstration using on-board data sets but can easily be adapted for users to work with their own data. 2.1 Before Starting 2.1.1 R Please install R by visiting www.r-project.org. We recommend that you use RStudio to interact with, and script in R. These documents were all made using R version 4.0.4 (2021-02-15). 2.1.2 Getting dplR Install the add-on library dplR. You can download and install these using the install.packages function from the R prompt: install.packages(&quot;dplR&quot;) These documents use version 1.6.8 of dplR. You can check the version of your version of dplR via: packageVersion(&quot;dplR&quot;) If your version is older you can update it (and all your other packages) in R via: update.packages() These documents were all made using the most up-to-date versions of the packages available on the Comprehensive R Archive Network. Updating regularly is good practice! 2.2 Getting Help with R These pages demonstrate some basic aspects of tree-ring analysis through executable examples with on-board data sets. After a basic introduction, you will have a chance to work through examples yourself or work on your own analysis. No prior R experience is necessary but for those who are new to R, we suggest using the resources at swirl as a way of starting to learn R. 2.3 Citing R, dplR, and other packages It’s important to cite software for any number of reasons. E.g., citing software let’s the reader know what you did and hopefully furthers the science; being specific about version number you used will help track down discrpenscies as software evoloves; and so on. There is a nifty citation() function in R that gives you information on how to best cite R and, in many cases, its packages. citation() ## ## To cite R in publications use: ## ## R Core Team (2021). R: A language and environment for statistical ## computing. R Foundation for Statistical Computing, Vienna, Austria. ## URL https://www.R-project.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {R: A Language and Environment for Statistical Computing}, ## author = {{R Core Team}}, ## organization = {R Foundation for Statistical Computing}, ## address = {Vienna, Austria}, ## year = {2021}, ## url = {https://www.R-project.org/}, ## } ## ## We have invested a lot of time and effort in creating R, please cite it ## when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for ## citing R packages. As the citation function indicates: “We have invested a lot of time and effort in creating R, please cite it when using it for data analysis.” The creation of dplR is an act of love. We enjoy writing this software and helping users. However, we are not among the idle rich. Alas. We have jobs and occasionally have to answer to our betters. We ask that you please cite dplR and R appropriately in your work. This way when our department chairs and deans accuse us of being dilettantes we can point to the use of dplR as a partial excuse. There is more detailed information available in the help files and in the literature (Bunn, 2008, 2010). citation(&quot;dplR&quot;) ## ## Bunn AG (2008). &quot;A dendrochronology program library in R (dplR).&quot; ## _Dendrochronologia_, *26*(2), 115-124. ISSN 1125-7865, doi: ## 10.1016/j.dendro.2008.01.002 (URL: ## https://doi.org/10.1016/j.dendro.2008.01.002). ## ## Bunn AG (2010). &quot;Statistical and visual crossdating in R using the dplR ## library.&quot; _Dendrochronologia_, *28*(4), 251-258. ISSN 1125-7865, doi: ## 10.1016/j.dendro.2009.12.001 (URL: ## https://doi.org/10.1016/j.dendro.2009.12.001). ## ## Andy Bunn, Mikko Korpela, Franco Biondi, Filipe Campelo, Pierre ## Mérian, Fares Qeadan and Christian Zang (2021). dplR: ## Dendrochronology Program Library in R. R package version 1.7.2. ## https://CRAN.R-project.org/package=dplR ## ## To see these entries in BibTeX format, use &#39;print(&lt;citation&gt;, ## bibtex=TRUE)&#39;, &#39;toBibtex(.)&#39;, or set ## &#39;options(citation.bibtex.max=999)&#39;. The same practice goes for any other add-on package you might use. "],["using-dplr.html", "Chapter 3 Using dplR 3.1 What is Covered 3.2 Working with Ring-Width Data 3.3 Descriptive Statistics 3.4 Detrending 3.5 Descriptive Statistics for Detrended Data 3.6 Building a Mean Value Chronology 3.7 Conclusion", " Chapter 3 Using dplR This document describes basic features of dplR by following the initial steps that an analyst might follow when working with a new tree-ring data set. The vignette starts with reading in ring widths and plotting them. We describe a few of the available methods for detrending and then show how to extract basic descriptive statistics. We show how to build and plot a simple mean-value chronology. We also show how to build a chronology using the expressed population signal from the detrended ring widths as an example of how more complicated analysis can be done using dplR. 3.1 What is Covered The Dendrochronology Program Library in R (dplR) is a package for dendrochronologists to handle data processing and analysis. This document gives just a brief introduction of some of the most commonly used functions in dplR. There is more detailed information available in the help files and in the literature (Bunn, 2008). In this vignette, we will walk through the most basic activities of working with tree-ring data in roughly the order that a user might follow. E.g., reading data, detrending, chronology building, and doing preliminary exploratory data analysis via descriptive statistics. 3.1.1 Load dplR We will be using dplR in here. Load it: library(dplR) 3.2 Working with Ring-Width Data 3.2.1 Reading Data There are many ways that tree-ring data are digitally stored. These range in sophistication from the simple (and commonly used) Tucson/decadal format file of ring widths to the more complex (but richer) TRiDaS format. The type of data used most often by dendrochronologists is a series of ring widths from tree cores. We generally refer to these as rwl objects for “ring width length” but there is no reason these cannot be other types of tree-ring data (e.g., density). The workhorse function for getting tree-ring data into R is dplR’s read.rwl function. This function reads files in \"tucson\", \"compact\", \"tridas\", and \"heidelberg\" formats. The on-board rwl data sets in dplR (i.e., co021, ca533, gp.rwl) were all imported into R using this function. Throughout this vignette we will use the on-board data set ca533 which gives the raw ring widths for bristlecone pine Pinus longaeva at Campito Mountain in California, USA. There are 34 series spanning 1358 years. These objects are structured very simply as a data.frame with the series in columns and the years as rows. The series IDs are the column names and the years are the row names (both stored as characters). For instance, using the Campito Mountain ring widths we can load the data and learn some basic things about it: data(ca533) # the result of ca533 &lt;- read.rwl(&#39;ca533.rwl&#39;) nrow(ca533) # 1358 years ## [1] 1358 ncol(ca533) # 34 series ## [1] 34 We can look a little deeper at this object (ca533) and get the series names as well as look at the time values associates with the data: colnames(ca533) # the series IDs ## [1] &quot;CAM011&quot; &quot;CAM021&quot; &quot;CAM031&quot; &quot;CAM032&quot; &quot;CAM041&quot; &quot;CAM042&quot; &quot;CAM051&quot; &quot;CAM061&quot; ## [9] &quot;CAM062&quot; &quot;CAM071&quot; &quot;CAM072&quot; &quot;CAM081&quot; &quot;CAM082&quot; &quot;CAM091&quot; &quot;CAM092&quot; &quot;CAM101&quot; ## [17] &quot;CAM102&quot; &quot;CAM111&quot; &quot;CAM112&quot; &quot;CAM121&quot; &quot;CAM122&quot; &quot;CAM131&quot; &quot;CAM132&quot; &quot;CAM141&quot; ## [25] &quot;CAM151&quot; &quot;CAM152&quot; &quot;CAM161&quot; &quot;CAM162&quot; &quot;CAM171&quot; &quot;CAM172&quot; &quot;CAM181&quot; &quot;CAM191&quot; ## [33] &quot;CAM201&quot; &quot;CAM211&quot; head(time(ca533),n = 10) # the first 10 years ## [1] 626 627 628 629 630 631 632 633 634 635 3.2.2 Describing and Plotting Ring-Width Data Once a rwl data set has been read into R, there are a variety of ways to describe and visualize those data. Take note that this object is stored both as a generic data.frame in R but it also is part of a special class called rwl which will let R know how to do some special things with it like summarize and plot the data: class(ca533) ## [1] &quot;rwl&quot; &quot;data.frame&quot; Thus, we can plot a rwl object by showing either the segments arranged over time as straight lines or as a “spaghetti plot.” The rwl objects have generic S3 methods for plot and summary meaning that R knows how to do something special when plot or summary are invoked on an object with class rwl. E.g.,: plot(ca533, plot.type=&quot;spag&quot;) 3.3 Descriptive Statistics The simplest report on a rwl object can be print to the screen via: rwl.report(ca533) ## Number of dated series: 34 ## Number of measurements: 23276 ## Avg series length: 684.6 ## Range: 1358 ## Span: 626 - 1983 ## Mean (Std dev) series intercorrelation: 0.6294 (0.08593) ## Mean (Std dev) AR1: 0.7093 (0.09812) ## ------------- ## Years with absent rings listed by series ## Series CAM011 -- 1753 1782 ## Series CAM031 -- 1497 1500 1523 1533 1540 1542 1545 1578 1579 1580 1655 1668 1670 1681 ## Series CAM032 -- 1497 1523 1579 1654 1670 1681 1782 ## Series CAM051 -- 1475 ## Series CAM061 -- 1497 1523 1542 1545 1547 1579 1654 1655 1668 1670 1672 1782 1858 1960 ## Series CAM062 -- 1542 1545 1547 1548 1579 1654 1655 1670 1672 1782 1836 1857 1858 1929 ## Series CAM071 -- 1269 1497 1498 1523 1542 1547 1578 1579 1612 1655 1656 1668 1670 1672 1674 1690 1707 1708 1756 1782 1795 1820 1836 1845 1857 1858 1924 1948 1960 ## Series CAM072 -- 1218 1497 1498 1523 1533 1538 1542 1545 1546 1547 1571 1579 1580 1590 1654 1655 1668 1670 1672 1675 1690 ## Series CAM081 -- 1218 1336 ## Series CAM082 -- 1362 1858 1865 ## Series CAM091 -- 1655 1669 1670 1782 1858 ## Series CAM092 -- 1624 1654 1655 1670 1672 1675 1677 1690 1703 1705 1707 1708 1710 1733 1753 1756 1757 1774 1777 1781 1782 1783 1784 1795 1807 1824 1829 1836 1845 1857 1858 1899 1904 1929 1936 1961 ## Series CAM101 -- 1782 1783 1899 1929 ## Series CAM102 -- 1669 1690 1782 1858 1899 1929 ## Series CAM111 -- 1542 ## Series CAM112 -- 1542 ## Series CAM121 -- 1093 1218 1254 1361 1365 1460 1462 1468 1473 1475 1492 1497 1542 1544 1545 1547 1600 1899 1960 ## Series CAM122 -- 1117 1133 1147 1177 1218 1254 1361 1475 1497 1670 ## Series CAM131 -- 1361 ## Series CAM151 -- 1670 1703 ## Series CAM161 -- 1523 ## Series CAM162 -- 1618 1624 1641 ## Series CAM181 -- 1450 1523 ## Series CAM191 -- 1475 1497 1523 1533 1542 1558 1571 1578 1618 1655 1668 1670 1675 1677 1690 1705 1777 1929 ## Series CAM201 -- 1523 ## Series CAM211 -- 645 762 809 847 924 957 1014 1118 1123 1133 1147 1189 1350 1384 1468 1571 1641 ## 234 absent rings (1.005%) ## ------------- ## Years with internal NA values listed by series ## None That’s pretty basic information. We can look at some common (and not-so common) descriptive statistics of a rwl object: ca533.stats &lt;- summary(ca533) # same as calling rwl.stats(ca533) head(ca533.stats,n=5) # look at the first five series ## series first last year mean median stdev skew gini ar1 ## 1 CAM011 1530 1983 454 0.440 0.40 0.222 1.029 0.273 0.696 ## 2 CAM021 1433 1983 551 0.424 0.40 0.185 0.946 0.237 0.701 ## 3 CAM031 1356 1983 628 0.349 0.29 0.214 0.690 0.341 0.808 ## 4 CAM032 1435 1983 549 0.293 0.26 0.163 0.717 0.309 0.661 ## 5 CAM041 1683 1983 301 0.526 0.53 0.223 0.488 0.238 0.690 These are common summary statistics like mean, median, etc. but also statistics that are more specific to dendrochronology like the first-order autocorrelation (ar1), gini (gini), and mean sensitivity (sens1 and sens2). We would be remiss if we did not here mention that mean sensitivity is actually a terrible statistic that should rarely, if ever, be used (Bunn et al., 2013). Note that output object ca533.stats is itself a data.frame and its data can be used to plot, etc. For instance, we can look at the spread of the first-order autocorrelation via summary(ca533.stats$ar1) or make a plot to show the data. Here we will demonstrate a somewhat involved plot to get you an idea of how to layer plotting commands: boxplot(ca533.stats$ar1,ylab=expression(phi[1]),col = &quot;lightblue&quot;) stripchart(ca533.stats$ar1, vertical = TRUE, method = &quot;jitter&quot;, jitter = 0.02,add = TRUE, pch = 20, col = &#39;darkblue&#39;,cex=1.25) ar1Quant &lt;- quantile(ca533.stats$ar1,probs = c(0.25,0.5,0.75)) abline(h=ar1Quant,lty=&quot;dashed&quot;,col=&quot;grey&quot;) mtext(text = names(ar1Quant),side = 4,at = ar1Quant,las=2) Quick editorial note. I’ve switched from base R plotting to using ggplot in most all of my work. I need to go through and provide new plotting examples for everything, but time is short. Real quick though, here is a ggplot library(ggplot2) ar1 &lt;- data.frame(x=&quot;CA 533&quot;,y=ca533.stats$ar1) ggplot(ar1,aes(x,y)) + geom_boxplot(width=.2) + geom_jitter(width=0.1) + labs(y=expression(phi[1]),x=element_blank()) + theme_minimal() 3.4 Detrending Analysts often (but not always) detrend a rwl data set to create an object containing ring-width index (rwi) values. The dplR package contains most standard detrending methods including detrending via splines, fitting negative exponential curves, and so on. There are also dplR functions for less commonly used detrending methods like regional curve standardization. There has been much hue and cry for having the “signal-free” method implemented in dplR and that should be done soon (he said optimistically). A rwi object has the same basic properties as the rwl object from which it is made. I.e., it has the same number of rows and columns, the same names, and so on. The difference is that each series has been standardized by dividing the ring widths against a growth model (e.g., a stiff spline, a negative exponential, etc.). This gives each series a mean of one (thus referred to as “indexed”) and allows a chronology to be built (next section). As read.rwl is the primary function for getting data into R, detrend is the primary function for standardizing rwl objects (but see cms, rcs, bai.in, and bai.out as well). 3.4.1 Common Detrending Methods As any dendrochronologist will tell you, detrending is a dark art. In dplR we have implemented some of the standard tools for detrending but all have drawbacks. In all of the methods, the detrending is the estimation and removal of the low frequency variability that is due to biological or stand effects. The standardization is done by dividing each series by the growth trend to produce units in the dimensionless ring-width index (RWI). Much of the text that follows is modified from the help page of detrend. Probably the most common method for detrending is what is often called the “conservative” approach of attempting to fit a negative exponential curve to a series. In the dplR implementation the \"ModNegExp\" method of detrend attempts to fit a classic nonlinear model of biological growth of the form \\((f(t) = a \\times \\mathrm{e}^{bt} + k)\\), where the argument of the function is time, using nls. See Fritts (2001) for details about the parameters. If a suitable nonlinear model cannot be fit (function is non-decreasing or some values are not positive) then a linear model is fit using lm. That linear model can have a positive slope unless pos.slope is FALSE in which case the series is standardized by its mean (method \"Mean\" in detrend). For instance, every series in the ca533 object can be detrended at once via: ca533.rwi &lt;- detrend(rwl = ca533, method = &quot;ModNegExp&quot;) This saves the results in ca533.rwi which is a data.frame with the same dimensions as the rwl object ca533 and each series standardized. nrow(ca533.rwi) # 1358 years ## [1] 1358 ncol(ca533.rwi) # 34 series ## [1] 34 colMeans(ca533.rwi, na.rm=TRUE) ## CAM011 CAM021 CAM031 CAM032 CAM041 CAM042 CAM051 CAM061 CAM062 CAM071 CAM072 ## 0.9996 1.0000 1.0000 1.0000 1.0000 1.0012 1.0002 0.9999 1.0000 1.0000 1.0000 ## CAM081 CAM082 CAM091 CAM092 CAM101 CAM102 CAM111 CAM112 CAM121 CAM122 CAM131 ## 1.0000 1.0000 1.0000 0.9996 1.0000 1.0000 1.0000 1.0000 1.0000 1.0000 0.9998 ## CAM132 CAM141 CAM151 CAM152 CAM161 CAM162 CAM171 CAM172 CAM181 CAM191 CAM201 ## 0.9985 0.9999 0.9995 0.9999 1.0004 0.9994 0.9997 0.9998 1.0000 0.9953 1.0000 ## CAM211 ## 0.9998 When detrend is run on a rwl object the function loops through each series. It does this by calling a different function (detrend.series) for each column in the rwl object. But, a user can also call detrend.series and it is useful to do so here for educational purposes. Let us detrend a single series and apply more than one detrending method when we call the detrend function. We will call detrend.series using the verbose mode so that we can see the parameters applied for each method. The detrend.series function produces a plot by default. CAM011.rwi &lt;- detrend.series(y = ca533[, &quot;CAM011&quot;],verbose=TRUE) ## Verbose output: ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Options ## make.plot TRUE ## method(s)1 c(&quot;Spline&quot;, &quot;ModNegExp&quot;, &quot;Mean&quot;, &quot;Ar&quot;, &quot;Friedman&quot;, &quot;ModHugershoff&quot; ## method(s)2 ) ## nyrs NULL ## f 0.5 ## pos.slope FALSE ## constrain.nls never ## verbose TRUE ## return.info FALSE ## wt default ## span cv ## bass 0 ## difference FALSE ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Zero indices in input series: ## 1128 1157 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by ModNegExp. ## Trying to fit nls model... ## nls coefs ## a: 0.66110 ## b: -0.01184 ## k: 0.31793 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by ModHugershoff. ## Trying to fit nls model... ## nls coefs ## a: 0.45550 ## b: 0.15420 ## g: 0.01532 ## d: 0.32392 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by spline. ## Spline parameters ## nyrs = 304, f = 0.5 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by mean. ## Mean = 0.4396 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by prewhitening. ## Call: ## ar(x = y[idx.goody]) ## ## Coefficients: ## 1 2 3 4 5 6 7 8 9 10 ## 0.388 0.139 0.000 0.084 0.132 0.061 0.038 -0.126 0.037 -0.100 ## 11 12 13 14 15 16 17 18 19 20 ## -0.010 0.015 0.088 0.010 0.064 -0.013 0.015 -0.004 -0.054 0.124 ## 21 22 23 ## -0.030 -0.054 0.137 ## ## Order selected 23 sigma^2 estimated as 0.0209 ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Detrend by FriedMan&#39;s super smoother. ## Smoother parameters ## span = cv, bass = 0 ## wt = default ## ## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## Zero indices in Ar series: ## 993 Note that advanced users can use return.info=TRUE to have all the curve-fitting parameters returned in a list. Having access to these curves is occasionally desirable. Also. sometimes, a user will want to interactively detrend each series and fit a negative exponential curve to one series, a spline to another, and the mean to a third. This can be done via the i.detrend and i.detrend.series functions. See their help pages for details. Advanced users can also power transform tree-ring data (powt) and detrend via subtraction instead of division using detrend and detrend.series. 3.4.2 Other Detrending Methods There are other detrending methods that are less commonly used but might have theoretical advantages. These include regional curve standardization (function rcs), C-Method Standardization (function cms), and converting measurements of ring widths to basal area increment (functions bai.in and bai.out). See their help pages for further information. 3.5 Descriptive Statistics for Detrended Data It is also easy in dplR to compute commonly used descriptive statistics that describe the correlation between series (both within and between tree correlations) as well as the expressed population signal and signal-to-noise ratio for a data set. These are done in dplR using the rwi.stats function so-named because these statistics are typically (but not always) carried out on detrended and standardized ring widths (rwi). If a data set has more than one core taken per tree this information can be used in the calculations to calculate within vs. between tree correlation. The function read.ids is used to identify which trees have multiple cores. ca533.ids &lt;- read.ids(ca533, stc = c(3, 2, 1)) rwi.stats(ca533.rwi, ca533.ids, prewhiten=TRUE) ## n.cores n.trees n n.tot n.wt n.bt rbar.tot rbar.wt rbar.bt c.eff rbar.eff ## 1 34 21 11.7 523 13 510 0.444 0.603 0.439 1.448 0.501 ## eps snr ## 1 0.922 11.75 There is (at least) one other way of looking at the average interseries correlation of a data set. The interseries.cor function in dplR gives a measure of average interseries correlation that is different from the rbar statistics from rwi.stats. In this function, correlations are calculated serially between each tree-ring series and a master chronology built from all the other series in the rwl object (leave-one-out principle). The average of those correlations is sometimes called the “overall interseries correlation” or even the “COFECHA correlation” in reference to commonly used crossdating software COFECHA. This number is typically higher than the various rbar values given by rwi.stats. We are showing just the first five series and the mean for all series here: ca533.rho &lt;- interseries.cor(ca533.rwi, prewhiten=TRUE, method=&quot;spearman&quot;) ca533.rho[1:5, ] ## res.cor p.val ## CAM011 0.5358 0 ## CAM021 0.6760 0 ## CAM031 0.5258 0 ## CAM032 0.6265 0 ## CAM041 0.4907 0 mean(ca533.rho[, 1]) ## [1] 0.6368 Again, if these concepts are unknown to you statistically look at some of the canonical works in dendrochronology like Cook et al. (1990), Fritts (2001), and Hughes et al. (2011). 3.6 Building a Mean Value Chronology After detrending, a user will typically build a chronology by averaging across the years of the rwi object. In dplR the function for doing this is chron which by default uses Tukey’s biweight robust mean (an average that is unaffected by outliers). ca533.crn &lt;- chron(ca533.rwi, prefix = &quot;CAM&quot;) This object has the same number of rows as the rwi object that was used as the input and two columns. The first gives the chronology and the second the sample depth (the number of series available in that year). dim(ca533.rwi) ## [1] 1358 34 dim(ca533.crn) ## [1] 1358 2 An object produced by chron has a generic S3 method for plotting which calls the crn.plot function (which has many arguments for customization). Here we will just make a simple plot of the chronology with a smoothing spline (function ffcsaps) added. plot(ca533.crn, add.spline=TRUE, nyrs=20) 3.7 Conclusion In general this page aims to give a very cursory overview of basic tasks that most dendrochronologists will want to be aware of. Know that we are just scratching the surface of what dplR is capable of. As a small example, here is a way that a user might decide to truncate a chronology based on the subsample signal strength. ca533.sss &lt;- sss(ca533.rwi,ca533.ids) yr &lt;- time(ca533) par(mar = c(2, 2, 2, 2), mgp = c(1.1, 0.1, 0), tcl = 0.25, xaxs=&#39;i&#39;) plot(yr, ca533.crn[, 1], type = &quot;n&quot;, xlab = &quot;Year&quot;, ylab = &quot;RWI&quot;, axes=FALSE) cutoff &lt;- max(yr[ca533.sss &lt; 0.85]) xx &lt;- c(500, 500, cutoff, cutoff) yy &lt;- c(-1, 3, 3, -1) polygon(xx, yy, col = &quot;grey80&quot;) abline(h = 1, lwd = 1.5) lines(yr, ca533.crn[, 1], col = &quot;grey50&quot;) lines(yr, ffcsaps(ca533.crn[, 1], nyrs = 32), col = &quot;red&quot;, lwd = 2) axis(1); axis(2); axis(3); par(new = TRUE) ## Add SSS plot(yr, ca533.sss, type = &quot;l&quot;, xlab = &quot;&quot;, ylab = &quot;&quot;, axes = FALSE, col = &quot;blue&quot;) abline(h=0.85,col=&quot;blue&quot;,lty=&quot;dashed&quot;) axis(4, at = pretty(ca533.sss)) mtext(&quot;SSS&quot;, side = 4, line = 1.1, lwd=1.5) box() We hope that this helps users cover introductory data handling and processing using dplR and R. As we noted above we are just providing a short introduction as to what is possible in dplR. There are many other functions in dplR that will help users analyze tree rings. These include a host of functions for statistical cross dating as well as spectral and wavelet analysis. You can see other vignettes for dplR via: vignette(package=&quot;dplR&quot;) And if you were interested in ARMA models, wavelets, and spectral analysis for tree rings you might want to display a PDF of the vignette on time-series analysis via: vignette(topic=&quot;timeseries-dplR&quot;,package=&quot;dplR&quot;) Or just extract the code via: edit(vignette(topic=&quot;timeseries-dplR&quot;,package=&quot;dplR&quot;)) "],["xdate.html", "Chapter 4 xDate 4.1 Introduction 4.2 Ruining a Perfectly Good Data Set 4.3 Series Correlation by Segment 4.4 Individual Series Correlation 4.5 Using Cross Correlation 4.6 Visual Crossdating 4.7 Conclusion", " Chapter 4 xDate In this vignette we cover basic crossdating techniques in dplR by deliberately misdating one of the series in a well-dated set of ring widths and tracking down the dating error. As with any dating enterprise, statistical crossdating is merely a tool and users should always rely on the wood to accurately date tree-ring data. 4.1 Introduction This gives an introduction of some of the crossdating functions in dplR. This is essentially a rehashing of Bunn (2010). Please cite that paper if you use dplR for crossdating. There is more detailed information on all these functions in the help files. 4.1.1 Load dplR We will be usinf dplR in here. Load it: library(dplR) 4.2 Ruining a Perfectly Good Data Set Throughout this vignette we will use the on-board data set co021 which gives the raw ring widths for Douglas fir Pseudotsuga menziesii at Mesa Verde in Colorado, USA. There are 35 series spanning 788 years. We will rename the co021 object to dat because we are going to mess around with it and it seems like good practice to rename it. data(co021) dat &lt;- co021 dat.sum &lt;- summary(dat) mean(dat.sum$year) ## [1] 564.9 mean(dat.sum$stdev) ## [1] 0.3232 mean(dat.sum$median) ## [1] 0.3211 mean(dat.sum$ar1) ## [1] 0.6038 mean(interseries.cor(dat)[, 1]) ## [1] 0.8478 plot(dat, plot.type=&quot;spag&quot;) We can see that this is a beautifully sensitive collection with long segment lengths, high standard deviation (relative to ring widths), large first-order autocorrelation, and a high mean interseries correlation (\\(\\mathrm{r}\\approx 0.84\\)). To demonstrate how crossdating works in dplR, we will take this perfectly lovely data set and corrupt the dating of one of the series. By doing so we will be able to reenact one of the most common tasks of the dendrochronologist: tracking down a misdated core. Here we will take a random series and remove one of the years of growth. This simulates a missing ring in the series. We will pick a random year in the core to give us a bit of a challenge in finding it. set.seed(4576) i &lt;- sample(x=nrow(dat), size=1) j &lt;- sample(x=ncol(dat), size=1) tmp &lt;- dat[, j] tmp &lt;- c(NA, tmp[-i]) dat[, j] &lt;- tmp We have now deleted the \\(i^{th}\\) observation from the \\(j^{th}\\) core while making sure that dat still has the appropriate numbers of rows. By sticking the NA at the start of the series it is as if we missed a ring while measuring. 4.3 Series Correlation by Segment The primary function for looking the crossdating of a tree-ring data set in dplR is corr.rwl.seg. This function looks at the correlation between each tree-ring series and a master chronology built from all the other series in the rwl object (leave-one-out principle). These correlations are calculated on overlapping segments (e.g., 50-year segments would be overlapped by 25 years). By default, each of the series is filtered to remove low-frequency variation prior to the correlation analysis. The help file has abundant details. Here we will look at overlapping 60 year segments. A plot is produced by default with corr.rwl.seg. In the corr.rwl.seg plot, each segment of each series is shown and colored by its correlation with the master. Each series is represented by two courses of lines with the bottom course adhering to the bottom axis timeline and the top course matching the upper axis timeline. Segments are colored according to the strength of the correlation between that segment and the master chronology. Blue correlates well (p-values less or equal to the user-set critical value) while potential dating problems are indicated by the red segments (p-values greater than the user-set critical value). Green lines show segments that do not completely overlap the time period and thus have no correlations calculated. Our modified data set indicates one series with dating problems. rwl.60 &lt;- corr.rwl.seg(dat, seg.length=60, pcrit=0.01) In this figure, each 60-year segment of each series in the modified Mesa Verde data set is shown and colored by its correlation with the master. Our modified data set indicates one series with dating problems. 4.4 Individual Series Correlation The low correlation between series 643114 and the master indicates a dating problem. Now that we suspect a dating problem, let us take a closer look at this problem child. The figure above shows that series 643114 begins to lose correlation with the master at the end of the 19th century. seg.60 &lt;- corr.series.seg(rwl=dat, series=&quot;643114&quot;, seg.length=60) Correlations between series 643114 and the master chronology are shown with horizontal lines according (60-year segments lagged by 30 years). A centered running correlation with a length of 60 years complements the segment correlations. The critical level is shown with a dashed line. 4.5 Using Cross Correlation This figure strongly indicates that the dating in the series 643114 begins to deteriorate between 1850 and 1910. We can create a window (win) of years and subset dat to the window if years we want to look at. Then we can look more closely at this time period and compute a cross-correlation function to look at lagged correlations to see if we can spot the dating problem. win &lt;- 1800:1960 dat.yrs &lt;- time(dat) dat.win &lt;- subset(dat,dat.yrs %in% win) ccf.30 &lt;- ccf.series.rwl(rwl=dat.win, series=&quot;643114&quot;, seg.length=30, bin.floor=50) ## NB: With series.x = FALSE (default), negative lags indicate missing rings in series Cross-correlations between series 643114 and the master chronology are shown for each segment (30-year segments lagged by 15 years). The series correlates well at lag 0 until the 1865–1894 bin and then at lag +1 prior to 1865. This figure shows that 1865 to 1894 is the misdated part of this series. The lag of +1 over a lag of 0 indicates that the series 643114 is missing a ring as it better correlates to the master chronology with a one-year offset.1 Using a smaller time window and shorter correlation segments we can try to further isolate the switch from correlation at lag 0 to lag +1. We will, of course, have to be very careful about using such short segments for correlation and be ready to adjust our expectations accordingly. Fortunately, in this case the trees are so exquisitely sensitive that we can look at 20-year segments with some confidence. win &lt;- 1850:1900 dat.win &lt;- subset(dat,dat.yrs %in% win) ccf.20 &lt;- ccf.series.rwl(rwl=dat.win, series=&quot;643114&quot;, seg.length=20, bin.floor=0) ## NB: With series.x = FALSE (default), negative lags indicate missing rings in series Cross-correlations between series `643114’ and the master chronology at 20-year segments lagged by 10 years over 1850–1900. By 1879 the correlation between series 643114 and the master is solidly at lag +1. The 1870 to 1889 correlation is marginal while the dating at 1880–1899 seems accurate (lag 0). This suggests that the dating error is between 1879 and 1889. At this point we could repeat the cross-correlation using even more carefuly to get even closer to the bad year if we wanted to. But at this point going and looking at the wood in that neighborhood would be the best option. Statistics only gets you so far. 4.6 Visual Crossdating We have strong inference now that series 643114 is misdated somewhere in a ten year period around 1885. One final tool that dplR has is the ability to combine the visual style of crossdating using skeleton plots with the statistical approach of cross-correlation analysis. The skel.ccf.plot function does just this. Here we make a skeleton plot from the 40-year period around the suspected dating error (1885): xskel.ccf.plot(rwl=dat, series=&quot;643114&quot;, win.start=1865, win.width=40) The top panel shows the normalized values for the master chronology (bottom half) and the series 643114 (top half) in green. The values are relative. Similarly, the black lines are a skeleton plot for the master and series with the marker years annotated for the master on the bottom axis and series 643114 on the top. The text at the top of the figure gives the correlation between the series and master (green bars) as well as the percentage of agreement between the skeleton bars for the series and master. The bottom panels show cross correlations for the first half (left) and second half of the time series. In this case, the early period (1865–1884) shows a mismatch of the skeleton plot by one year coupled with a strong lag +1 correlation. At this point the analyst would go to the wood and take a good look at the core and see what they could find out. There are more heroic efforts that one could go to to figure out exactly where the dating problem might be but nothing ever takes the place of looking at the sample! 4.7 Conclusion We have strong inference now that series 643114 is misdated somewhere in a ten year period around 1885. We have still not revealed whether this is correct or not. Let us look at the values for i and j and see how we did: j ## [1] 13 colnames(co021)[j] ## [1] &quot;643143&quot; i ## [1] 557 rownames(co021)[i] ## [1] &quot;1732&quot; Our sleuthing indicated that our dating error was around the year 1885. In fact, i was the year 1884. As of dplR version 1.60, the cross correlations in ccf.series.rwl are calculated calling ccf(x=series, y=master, lag.max=lag.max, plot=FALSE). Note that prior to dplR version 1.60, the master was set as x and the series as y. This was changed to be more in line with user expectations so that a missing ring in a series produces a positive lag in the plot rather than a negative lag. This structure of this call does put the plots at odds with Figure 3 in Bunn (2010) which is unfortunate.↩︎ "],["intro-to-dendro-time-series.html", "Chapter 5 Intro to dendro time-series 5.1 Introduction 5.2 Data Sets 5.3 Smoothing 5.4 Characterizing Temporal Structure 5.5 Frequency Domain", " Chapter 5 Intro to dendro time-series In this document we cover some of the basic time series tools in dplR. These include spectral analysis using redfit and wavelets. We also show off a few tools in other R packages like fitting AR and ARMA models, and Butterworth filters. However, this is just a tiny glimpse of tree-ring tools that exist in R. 5.1 Introduction The Dendrochronology Program Library in R (dplR) is a package for dendrochronologists to handle data processing and analysis. This document gives an introduction of some of the functions dealing with time series in dplR and looks at some functions other packages. However, this document does not purport to be any sort of authority on time series analysis at all! There are many wonderful R-centric books on time series analysis that can tell you about the theory and practice of working with time-series data. This is kind of a greatest hits of time-series tools that are commonly used in dendro, and not a reference text of any kind. 5.1.1 Load libraries We will be using dplR in here as well as a few other packages that are useful for working with time-series data. If you haven’t installed these packages yet you will want to using the install.packages() function. library(dplR) 5.2 Data Sets Throughout this vignette we will use the on-board data set co021 which gives the raw ring widths for Douglas fir Pseudotsuga menziesii at Mesa Verde in Colorado, USA. There are 35 series spanning 788 years. data(co021) co021.sum &lt;- summary(co021) head(co021.sum) ## series first last year mean median stdev skew gini ar1 ## 1 641114 1270 1963 694 0.287 0.23 0.231 2.884 0.372 0.686 ## 2 641121 1250 1963 714 0.328 0.26 0.315 3.306 0.410 0.744 ## 3 641132 1256 1963 708 0.357 0.29 0.337 4.741 0.373 0.686 ## 4 641143 1237 1963 727 0.344 0.27 0.287 2.341 0.397 0.708 ## 5 642114 1243 1963 721 0.281 0.24 0.219 2.848 0.358 0.673 ## 6 642121 1260 1963 704 0.313 0.21 0.416 4.399 0.474 0.865 plot(co021, plot.type=&quot;spag&quot;) These data are gorgeous with long segments (564), high interseries correlation (0.6), and high first-order autocorrelation (0.85). Let us make a mean-value chronology of the co021 data after detrending each series with a frequency response of 50% at a wavelength of 2/3 of each series’s length. co021.rwi &lt;- detrend(co021, method=&quot;Spline&quot;) co021.crn &lt;- chron(co021.rwi, prefix=&quot;MES&quot;) We can plot the chronology with a smoothing spline with a 20-year period: plot(co021.crn, add.spline=TRUE, nyrs=20) 5.3 Smoothing Very often one wants to smooth data to analyze or work only with particular aspects of the data. This kind of analysis is a big deal in time-series analysis. Smoothing is a way of isolating different frequencies of data but still thinking in the time domain. One such mark that we already alluded to above is the use of smoothing splines to detrend and filter tree-ring data. The urge to smooth a time series when we plot it is almost irresistible. It’s a sickness that dendro folks have. There are many different ways of smoothing and we will look at couple here. The co021.crn object has two columns, the first giving the chronology and the second the sample depth during that year. Let’s grab the years and the standard chronology and store them in their own objects. yrs &lt;- time(co021.crn) dat &lt;- co021.crn$MESstd 5.3.1 Moving (running) average Centered moving averages (aka running averages) tend to be the first smoothing method that most people learn. Let’s revisit them. These have the advantage of being dirt simple. Below we will see that they emphasize low frequency in the examples below (at 32, 64, and 128 years) but retain some jaggedness too. We will use the base filter function which is a straightforward convolution filter. As with any function always you can see the help file for details (?filter). ma32 &lt;- filter(x=dat, filter=rep(x=1/32,times=32), sides=2) ma64 &lt;- filter(x=dat, filter=rep(x=1/64,times=64), sides=2) ma128 &lt;- filter(x=dat, filter=rep(x=1/128,times=128), sides=2) # Change plotting parameters par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5, xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) my.cols &lt;- c(&quot;#1B9E77&quot;, &quot;#D95F02&quot;, &quot;#7570B3&quot;) plot(yrs,dat,type=&quot;l&quot;,xlab=&quot;Year&quot;,ylab=&quot;RWI&quot;,col=&quot;grey&quot;) abline(h=1) lines(yrs,ma128, col = my.cols[1], lwd = 2) lines(yrs,ma64, col = my.cols[2], lwd = 2) lines(yrs,ma32, col = my.cols[3], lwd = 2) axis(3);axis(4) 5.3.2 Hanning The Hanning filter is similar to the moving average in the sense that the curve emphasizes low frequency variability and loses the jaggedness over the moving average. It’s also a simple filter (look at the code by typing hanning at the R prompt) but it also is a start into thinking in the frequency domain. It’s part of a family of functions called window functions that are zero-valued outside of some interval chosen by the user. It’s used quite a bit by time-series wonks and it is implemented in dplR with the function hanning. I’ll skip the theory here but it’s a great precursor to the work we will do with spectral analysis below. han32 &lt;- hanning(dat,n=32) han64 &lt;- hanning(dat,n=64) han128 &lt;- hanning(dat,n=128) par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5, xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) plot(yrs,dat,type=&quot;l&quot;,xlab=&quot;Year&quot;,ylab=&quot;RWI&quot;,col=&quot;grey&quot;) abline(h=1) lines(yrs,han128, col = my.cols[1], lwd = 2) lines(yrs,han64, col = my.cols[2], lwd = 2) lines(yrs,han32, col = my.cols[3], lwd = 2) axis(3);axis(4) Like the moving average the smooth is shorter than the input data. This is too bad because it is nice to preserve the ends of the data but there is much wringing of hands and gnashing of teeth about the “right” way of running a smoothing algorithm where the data are sparse. This end-member problem is the subject of a lot of work in the time-series literature. head(data.frame(dat,ma32, han32), n = 20) ## dat ma32 han32 ## 1 1.0644 NA NA ## 2 0.9241 NA NA ## 3 0.9602 NA NA ## 4 0.8011 NA NA ## 5 1.2448 NA NA ## 6 1.3222 NA NA ## 7 0.4193 NA NA ## 8 0.7125 NA NA ## 9 1.0207 NA NA ## 10 0.9851 NA NA ## 11 0.4199 NA NA ## 12 0.7638 NA NA ## 13 1.4655 NA NA ## 14 1.0005 NA NA ## 15 1.0725 NA NA ## 16 0.4987 0.9226 0.9609 ## 17 0.6365 0.9167 0.9648 ## 18 0.7509 0.9147 0.9667 ## 19 2.0863 0.9205 0.9665 ## 20 1.2892 0.9464 0.9644 tail(data.frame(dat,ma32, han32), n = 20) ## dat ma32 han32 ## 769 1.0528 0.9214 0.9836 ## 770 0.9065 0.9094 0.9761 ## 771 0.4347 0.8989 0.9660 ## 772 1.1876 0.8883 0.9533 ## 773 1.1743 NA NA ## 774 1.7610 NA NA ## 775 0.6408 NA NA ## 776 0.1934 NA NA ## 777 1.3441 NA NA ## 778 0.4973 NA NA ## 779 0.7076 NA NA ## 780 0.7565 NA NA ## 781 0.5028 NA NA ## 782 1.0647 NA NA ## 783 1.1284 NA NA ## 784 0.1459 NA NA ## 785 1.1805 NA NA ## 786 0.7720 NA NA ## 787 0.6233 NA NA ## 788 0.6441 NA NA 5.3.3 Splines In the world of tree rings, you’ll see frequent mention of cubic smoothing splines and typically a citation for something by Ed Cook who is the greatest quantitative dendrochronologist of all time. His work has left an enduring mark on nearly every aspect of quantitative dendrochronology. For splines, Cook and Peters (1981) is the canonical citation but we would point you to Cook and Kairiukstis (Cook et al., 1990) for an overview. An R implementation of this spline is implemented in dplR with the ffcsaps function.2 The nyrs argument fits a spline of that many “years” to the data. (All the functions in dplR assume annual resolution but they don’t really care if you are using data with a different frequency.) spl128 &lt;- ffcsaps(dat,nyrs=128) spl64 &lt;- ffcsaps(dat,nyrs=64) spl32 &lt;- ffcsaps(dat,nyrs=32) par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5, xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) my.cols &lt;- c(&quot;#1B9E77&quot;, &quot;#D95F02&quot;, &quot;#7570B3&quot;) plot(yrs,dat,type=&quot;n&quot;,xlab=&quot;Year&quot;,ylab=&quot;RWI&quot;,axes=FALSE) grid(col=&quot;black&quot;,lwd=0.5) abline(h=1) lines(yrs,dat,col=&quot;grey&quot;,lwd=1) lines(yrs,spl128,col=my.cols[1],lwd=2) lines(yrs,spl64,col=my.cols[2],lwd=2) lines(yrs,spl32,col=my.cols[3],lwd=2) axis(1);axis(2);axis(3);axis(4) legend(&quot;topright&quot;, c(&quot;dat&quot;, &quot;128yrs&quot;, &quot;64yrs&quot;, &quot;32yrs&quot;), lwd = 2, col = c(&quot;grey&quot;,my.cols),bg = &quot;white&quot;) box() 5.3.4 Loess We will highlight a filter used commonly in time-series analysis but largely ignored in dendro. We’ve become increasingly fond of the loess smoother which uses a local, linear polynomial fit to smooth data. The parameter to adjust is the span f. Because f is the proportion of points used in the smoothing, the smaller the number the less smooth the curve will be. E.g., our series is 788 years long. If we want something that approaches a 25-year smooth we can take 25 over 788 and use 0.0317 of the points in the fit. n &lt;- length(yrs) f128 &lt;- 128/n f128.lo &lt;- lowess(x = yrs, y = dat, f = f128) f64 &lt;- 64/n f64.lo &lt;- lowess(x = yrs, y = dat, f = f64) f32 &lt;- 32/n f32.lo &lt;- lowess(x = yrs, y = dat, f = f32) par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5,xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) plot(yrs,dat,type=&quot;n&quot;,xlab=&quot;Year&quot;,ylab=&quot;RWI&quot;,axes=FALSE) grid(col=&quot;black&quot;,lwd=0.5) abline(h=1) lines(yrs,dat,col=&quot;grey&quot;,lwd=1) lines(yrs,f128.lo$y,col=my.cols[1],lwd=2) lines(yrs,f64.lo$y,col=my.cols[2],lwd=2) lines(yrs,f32.lo$y,col=my.cols[3],lwd=2) axis(1);axis(2);axis(3);axis(4) legend(&quot;topright&quot;, c(&quot;dat&quot;, &quot;f128&quot;, &quot;f64&quot;, &quot;f32&quot;), lwd = 2, col = c(&quot;grey&quot;,my.cols),bg = &quot;white&quot;) box() These smoothing lines above are essentially eye candy. We can and will use filtering for more sophisticated analysis below but let’s back up. 5.4 Characterizing Temporal Structure 5.4.1 ACF and PACF Let’s start with a quick exploratory data analysis into the time-series process. We will start our analysis on the chronology by looking at its autocorrelation structure using R’s acf and pacf functions. par(mfcol=c(1, 2)) acf(dat) pacf(dat) The ACF function indicates significant autocorrelation out to a lag of about 10 years (which is not uncommon in tree-ring data) while the PACF plot suggests that the persistence after lag 4 is due to the propagation of the autocorrelation at earlier lags. And one could very well argue that the best model here is an AR(2) model given the marginal significance of the PACF value at lags 3 and 4. After all, you can get three opinions by asking one statistician to look a time series. But we digress. We now have the first bit of solid information about the time-series properties of these data, it looks like they fit an AR(4) model. 5.4.2 AR and ARMA But, R being R, there are many other ways to check this. The easiest way is to use the ar function which fits an autoregressive models up to a specified order and selects the final model by AIC. dat.ar &lt;- ar(dat,order.max = 10) dat.ar ## ## Call: ## ar(x = dat, order.max = 10) ## ## Coefficients: ## 1 2 3 4 ## 0.200 0.148 0.046 0.075 ## ## Order selected 4 sigma^2 estimated as 0.188 Indeed, ar selects an AR(4) model based on AIC. But as our tea-leaf gazing above indicates, an AR(2) model is very close when we look at the AIC values. plot(0:10,dat.ar$aic,type=&quot;b&quot;,xlab=&quot;AR Order&quot;,ylab=&quot;AIC&quot;, main=&quot;Difference in AIC between each model and the best-fitting model&quot;) A strong argument can be made that a model with fewer parameters (e.g., an AR(2) might serve to characterize the data better than a model with more parameters. We could also fit these models as ARIMA models individually using the arima function. That function will fit a model with components (p, d, q) as the AR order, the degree of difference, and the MA order. Thus, we could fit AR(1) to AR(4) models: ar1 &lt;- arima(dat,order=c(1,0,0)) ar2 &lt;- arima(dat,order=c(2,0,0)) ar3 &lt;- arima(dat,order=c(3,0,0)) ar4 &lt;- arima(dat,order=c(4,0,0)) # example output ar1 ## ## Call: ## arima(x = dat, order = c(1, 0, 0)) ## ## Coefficients: ## ar1 intercept ## 0.260 0.975 ## s.e. 0.034 0.021 ## ## sigma^2 estimated as 0.195: log likelihood = -473.7, aic = 953.3 And then compare the Bayesian Information Criterion (BIC) values: BIC(ar1,ar2,ar3,ar4) ## df BIC ## ar1 3 967.3 ## ar2 4 949.9 ## ar3 5 953.5 ## ar4 6 955.8 Here we find evidence for an AR(2) model over the AR(4) mode that the ar function chose. Clearly there is some wiggle room here. So as we’ve seen, in addition to AR models we can fit their more complicated cousins, ARIMA models, as well. We can do the same sort of automatic selection of the model order by automatically fitting an ARIMA model using the auto.arima function in the package forecast. As with ar, this will choose a model that minimizes an information criterion after searching over user given constraints. We will use the default search parameters and use BIC to select the model. library(forecast) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo dat.arima &lt;- auto.arima(dat, ic=&quot;bic&quot;) summary(dat.arima) ## Series: dat ## ARIMA(1,0,1) with non-zero mean ## ## Coefficients: ## ar1 ma1 mean ## 0.827 -0.634 0.974 ## s.e. 0.050 0.068 0.032 ## ## sigma^2 estimated as 0.187: log likelihood=-457.1 ## AIC=922.2 AICc=922.3 BIC=940.9 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 7.679e-05 0.4322 0.3427 -457.9 481.3 0.7942 -0.0004114 Even more confusion! Instead of an AR(p) model, auto.arima went for an ARMA(1,1) model (aka ARIMA(1,0,1)). The parsimony principle certainly likes a nice simple ARMA(1,1) model. Note that we could look at the residuals, model coefficients, etc. quite easily. And indeed the residuals are quite clean as we would expect. acf(residuals(dat.arima)) This is clearly an incredibly shallow look at a deep topic. Hopefully these will get you started with different tools to characterize temporal structure in data. There are many more resources available and techniques we haven’t covered (e.g., GARCH modelling). 5.5 Frequency Domain Any time series can be broken down into a (possibly infinite) set of sine and cosine functions. So, a messy looking series like co021.crn is the sum of oscillating functions. The act of breaking these down is exactly what a Fourier transform does. Fourier transforms are everywhere – think JPEGs and MP3s. But we can use them to see what frequencies are important or dominant in a time series. Someday we will work up the courage to write a tutorial on fast Fourier transforms for dendro using R. It’s hard to know where to start with tackling the subject though as many of the tools that people want for dendro start with fft(dat) but don’t end there. With tree-ring data we often use spectral analysis as a way of detecting periodic signals that are corrupted by noise. 5.5.1 Power via Spectral Analysis and Wavelets Given the above rationale, we will limit ourselves here to some of the tools that are used in dendro without building these up from the fast Fourier transform itself. In dplR, we’ve implemented two of the most common ways that dendrochronologists go about this and there are a host of other approaches in R that we won’t get to here. The redfit function in dplR is a port of Schulz’s REDFIT (version 3.8e) program and estimates the red-noise spectrum of a time series (Schulz &amp; Mudelsee, 2002) with optional testing of that spectrum against a red-noise background using Monte Carlo simulations. redf.dat &lt;- redfit(dat, nsim = 1000) par(tcl = 0.5, mar = rep(2.2, 4), mgp = c(1.1, 0.1, 0),xaxs=&quot;i&quot;) plot(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], ylim = range(redf.dat[[&quot;ci99&quot;]], redf.dat[[&quot;gxxc&quot;]]), type = &quot;n&quot;, ylab = &quot;Spectrum&quot;, xlab = &quot;Frequency (cycles per year)&quot;, axes = FALSE) grid() lines(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], col = &quot;black&quot;,lwd=1.5) lines(redf.dat[[&quot;freq&quot;]], smooth.spline(redf.dat[[&quot;ci99&quot;]],spar = 0.8)$y, col = &quot;#D95F02&quot;) lines(redf.dat[[&quot;freq&quot;]], smooth.spline(redf.dat[[&quot;ci95&quot;]],spar = 0.8)$y, col = &quot;#7570B3&quot;) lines(redf.dat[[&quot;freq&quot;]], smooth.spline(redf.dat[[&quot;ci90&quot;]],spar = 0.8)$y, col = &quot;#E7298A&quot;) freqs &lt;- pretty(redf.dat[[&quot;freq&quot;]]) pers &lt;- round(1 / freqs, 2) axis(1, at = freqs, labels = TRUE) axis(3, at = freqs, labels = pers) mtext(text = &quot;Period (year)&quot;, side = 3, line = 1.1) axis(2); axis(4) legend(&quot;topright&quot;, c(&quot;dat&quot;, &quot;CI99&quot;, &quot;CI95&quot;, &quot;CI90&quot;), lwd = 2, col = c(&quot;black&quot;, &quot;#D95F02&quot;, &quot;#7570B3&quot;, &quot;#E7298A&quot;), bg = &quot;white&quot;) box() Using the Mesa Verde chronology we see that there are frequencies in that time series that are significantly different from a red-noise assumption in the interannual (&lt;3 years) and at low frequencies (multidecadal). Another popular way to visualize a tree-ring chronology in the frequency domain is through a continuous wavelet transform. In dplR, there is are functions for calculating the transform via wavelet and plotting the result via wavelet.plot. out.wave &lt;- morlet(y1 = dat, x1 = yrs, p2 = 8, dj = 0.1, siglvl = 0.99) wavelet.plot(out.wave, useRaster=NA, reverse.y = TRUE) The wavelet plot shows a similar story as the plot from redfit with significant variation at interannual to multidecadal scales. 5.5.2 Extracting signals Another common task we’ll mention here is extracting specific frequency components from a time series to look at different aspects of say, high vs low frequency growth. One approach to doing this is to use wavelets again but here we will decompose a time series into its constituent voices using a discrete wavelet transform with the mra function in the package waveslim. library(waveslim) ## ## waveslim: Wavelet Method for 1/2/3D Signals (version = 1.8.2) nPwrs2 &lt;- trunc(log(n)/log(2)) - 1 dat.mra &lt;- mra(dat, wf = &quot;la8&quot;, J = nPwrs2, method = &quot;modwt&quot;, boundary = &quot;periodic&quot;) yrsLabels &lt;- paste(2^(1:nPwrs2),&quot;yrs&quot;,sep=&quot;&quot;) par(mar=c(3,2,2,2),mgp=c(1.25,0.25,0),tcl=0.5,xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) plot(yrs,rep(1,n),type=&quot;n&quot;, axes=FALSE, ylab=&quot;&quot;,xlab=&quot;&quot;, ylim=c(-3,38)) title(main=&quot;Multiresolution decomposition&quot;,line=0.75) axis(side=1) mtext(&quot;Years&quot;,side=1,line = 1.25) Offset &lt;- 0 dat.mra2 &lt;- scale(as.data.frame(dat.mra)) for(i in nPwrs2:1){ x &lt;- dat.mra2[,i] + Offset lines(yrs,x) abline(h=Offset,lty=&quot;dashed&quot;) mtext(names(dat.mra)[[i]],side=2,at=Offset,line = 0) mtext(yrsLabels[i],side=4,at=Offset,line = 0) Offset &lt;- Offset+5 } box() Here the Mesa Verde chronology is shown via an additive decomposition for each power of 2 from \\(2^1\\) to \\(2^8\\). Note that each voice is scaled to itself by dividing by its standard deviation in order to present them on the same y-axis. If the scale function were to be removed (and we leave that as an exercise to the reader) the variations between voices would be greatly reduced. Note the similarity in the continuous and discrete wavelet plots for the variation in the 64-year band around the year 1600 and the lower frequency variation at 128 years around the year 1400. 5.5.3 High-pass, low-pass, and bandpass filtering Another common technique used in tree-ring analysis is to filter data like we did above with moving averages, splines, and so on but doing so in the frequency domain explicitly rather than in the time domain. For instance, we might want to remove the high frequencies from a data set and leave the low frequencies (low-pass filtering) or vice versa (high-pass filtering). Or extract specific frequencies and discard others (band-pass and stop-pass filtering). Let’s look at the signal library.3 library(signal) ## ## Attaching package: &#39;signal&#39; ## The following object is masked from &#39;package:dplR&#39;: ## ## hanning ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, poly We can start low-pass filtering in R with the Butterworth filter. We will fit two 4th order filters with frequencies of 0.2 and 0.05. # here are two frequencies that we will use for demonstrating filtering f1 &lt;- 0.2 # period of 5 f2 &lt;- 0.05 # period of 20 # Initialize the butterworth filter. # Multiply freq by 2 f1Low &lt;- butter(n=4, W=f1*2, type=&quot;low&quot;) f2Low &lt;- butter(n=4, W=f2*2, type=&quot;low&quot;) # We will use filtfilt do run the filter. # But before that there is a wrinkle. We have to # mirror and extend the data near the edge to # avoid end effects. The matlab/octave versions do something # like this behind the scenes I think. Regardless, it # is a simple form of padding. n &lt;- length(dat) # create a pas that is adds a 1/4 of the length to the front and # back of the data. This can be tuned according to the freqs in question # and there is nothing special about 1/4 pad &lt;- floor(n/4) # pad the data datPad &lt;- c(dat[pad:1],dat,dat[n:(n-pad)]) # run the filter datF1Low &lt;- filtfilt(f1Low, datPad) datF2Low &lt;- filtfilt(f2Low, datPad) # unpad the filtered data datF1Low &lt;- datF1Low[(pad+1):(n+pad)] datF2Low &lt;- datF2Low[(pad+1):(n+pad)] par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5,xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) plot(yrs,dat,type=&quot;n&quot;,xlab=&quot;Year&quot;,ylab=&quot;&quot;,axes=FALSE) grid(col=&quot;black&quot;,lwd=0.5) abline(h=1) lines(yrs,dat,col=&quot;grey80&quot;,lwd=1) lines(yrs,datF1Low,col=my.cols[1],lwd=1.5) lines(yrs,datF2Low,col=my.cols[2],lwd=2) axis(1);axis(2);axis(3);axis(4) legend(&quot;topright&quot;, c(&quot;f &lt; 0.2&quot;, &quot;f &lt; 0.05&quot;), lwd = 2, col = c(my.cols[1:2]),bg = &quot;white&quot;) box() To satisfy ourselves that the low-pass filter did what we thought it should let’s look at the power spectrum of the filtered data for f1: redf.dat &lt;- redfit(datF1Low, mctest=FALSE) par(tcl = 0.5, mar = rep(2.2, 4), mgp = c(1.1, 0.1, 0),xaxs=&quot;i&quot;) plot(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], xlim=c(0,0.25), type = &quot;n&quot;, ylab = &quot;Spectrum&quot;, xlab = &quot;Frequency (cycles per year)&quot;, axes = FALSE) grid() lines(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], col = &quot;black&quot;,lwd=1.5) freqs &lt;- pretty(redf.dat[[&quot;freq&quot;]]) pers &lt;- round(1 / freqs, 2) axis(1, at = freqs, labels = TRUE) axis(3, at = freqs, labels = pers) mtext(text = &quot;Period (year)&quot;, side = 3, line = 1.1) axis(2); axis(4) box() We could repeat this with high-pass filters by changing type=\"high\" when we first make the filter. We could also filter to include only specified frequencies by providing the lower and upper bands. E.g., butter(n=4, W=c(f2,f1)*2, type=\"pass\"). f1f2Pass &lt;- butter(n=4, W=c(f2,f1)*2, type=&quot;pass&quot;) datPass &lt;- filtfilt(f1f2Pass, datPad) datPass &lt;- datPass[(pad+1):(n+pad)] par(mar=rep(2.5,4),mgp=c(1.2,0.25,0),tcl=0.5,xaxs=&quot;i&quot;,yaxs=&quot;i&quot;) plot(yrs,datPass,type=&quot;n&quot;,xlab=&quot;Year&quot;,ylab=&quot;&quot;,axes=FALSE) grid(col=&quot;black&quot;,lwd=0.5) abline(h=0) lines(yrs,datPass,col=my.cols[3],lwd=1.5) axis(1);axis(2);axis(3);axis(4) legend(&quot;topright&quot;, &quot;0.05 &lt; f &lt; 0.2&quot;, lwd = 2, col = c(my.cols[3]),bg = &quot;white&quot;) box() And as above, here is the power spectrum of the band-pass data: redf.dat &lt;- redfit(datPass, mctest=FALSE) par(tcl = 0.5, mar = rep(2.2, 4), mgp = c(1.1, 0.1, 0),xaxs=&quot;i&quot;) plot(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], xlim=c(0,0.25), type = &quot;n&quot;, ylab = &quot;Spectrum&quot;, xlab = &quot;Frequency (cycles per year)&quot;, axes = FALSE) grid() lines(redf.dat[[&quot;freq&quot;]], redf.dat[[&quot;gxxc&quot;]], col = &quot;black&quot;,lwd=1.5) freqs &lt;- pretty(redf.dat[[&quot;freq&quot;]]) pers &lt;- round(1 / freqs, 2) axis(1, at = freqs, labels = TRUE) axis(3, at = freqs, labels = pers) mtext(text = &quot;Period (year)&quot;, side = 3, line = 1.1) axis(2); axis(4) box() 5.5.3.1 Interruption: Duplicate function names Take a moment to look back at the messages given off from loading signal. There are times when two packages will have the same function names. For instance both the signal package and dplR have a function called hanning (which applies the hanning filter to a time series). When two libraries are loaded that have two functions with the same name, R has to decide which to use when the function is called from the command line. Thus if we type hanning at the prompt we will get the `hanning function from the signal library. Because signal was loaded after dplR the hanning function from signal gets primacy. The same goes for the signal functions filter and poly which have counterparts the library stats which is loaded when R is first started. This dual name phenomenon can occasionally (but only occasionally) be a hindrance if you forget that it has happened. For instance, the function hanning in signal doesn’t do the same thing as the function hanning does in dplR. If you were expecting the behavior of one and got the other you might break your scripts, confuse yourself, and spend time tracking down the error. So, pay attention to masking when you load a package. We can still access dplR’s version of hanning via dplR::hanning if you want it. The same goes for stats::filter, stats::poly, and so on. The gory details on the calculations for the spline are given in “Mathematical Details of Functions in dplR.” See the example section in the help file for ffcsaps to access the document.↩︎ But note the information on name masking that gets spit out when we do – see explanation in the next section.↩︎ "],["references.html", "Chapter 6 References", " Chapter 6 References "]]
